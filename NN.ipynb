{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106a3615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "import pyautogui as pag\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import os\n",
    "import sys  # zahvat\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os    \n",
    "import torch.nn.functional as F\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b686704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, *args): #получаем n массивов данных\n",
    "        cnt, labels, temp =0, [], []\n",
    "        self.data = []\n",
    "        for data in args: #выделяем по одному из них\n",
    "            self.data.extend(torch.tensor(data).type(torch.float32)) # преобразуем каждый в тензор и добавляем к общим данным\n",
    "#             print(len(data))\n",
    "            for j in range(len(data)):\n",
    "                labels.append(cnt) #присовим номера каждому подмассиву для проверки\n",
    "            cnt += 1\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bed8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.fc3 = nn.Linear(200, 32)\n",
    "        self.fc4 = nn.Linear(32, 2)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50342872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gesture = {0: \"Fist\",\n",
    "           1:\"Open palm\",\n",
    "           2:\"Окей\",\n",
    "           3:\"Жест 4\",\n",
    "          4:\"Жест 5\",\n",
    "          5:\"Жест 6\"}\n",
    "\n",
    "def Result_chek(neuro_res):\n",
    "    znak_num=len(neuro_res)\n",
    "    global gesture\n",
    "    answ = {}\n",
    "    for el in range(znak_num):\n",
    "        answ[el] = neuro_res[el]\n",
    "    res = answ.keys()\n",
    "#     print(answ.keys())\n",
    "#     print(list(answ.values()).index(max(neuro_res)))\n",
    "#     print(list(answ.keys())[list(answ.values()).index(max(neuro_res))])\n",
    "    return gesture[list(answ.values()).index(max(neuro_res))]#(\"Жест на экране:  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e66c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('dataset/stop2.txt').readline()\n",
    "f = json.loads(f)\n",
    "# print(len(f))\n",
    "\n",
    "f = open('dataset/kulaksgat2.txt').readline()\n",
    "f = json.loads(f)\n",
    "# print(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b66dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, temp = [],[]\n",
    "gests = os.listdir('dataset')\n",
    "for gest in gests:\n",
    "    data = []\n",
    "#     print(gest)\n",
    "    f = open('dataset/' + str(gest)).readline()\n",
    "    f = json.loads(f)\n",
    "    for i in range (len(f)):\n",
    "        data.append(f[i])\n",
    "    temp.append(data)\n",
    "data = np.array(temp, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "021fd731",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(*data)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d80510f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training 8.359541530555958e-06\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for samples, labels in dataloader:\n",
    "        #print(samples,labels)\n",
    "        pred = net(samples)\n",
    "        loss = criterion(pred, labels)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "#     print(running_loss)\n",
    "print('Finished Training', running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4292e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "import pyautogui as pag\n",
    "import cv2\n",
    "import keyboard\n",
    "\n",
    "def smooth_mouse(x,y, ox, oy, sens):\n",
    "    speed_x = x - ox if x - ox > 0 else ox - x\n",
    "    speed_y = y - oy if y - oy > 0 else oy- y\n",
    "    dur = 1 - (max(speed_y, speed_x))\n",
    "#     print(sens)\n",
    "    shift = (x-ox) * sens[0], (y - oy) * sens[1] * 0,5\n",
    "#     print(shift)\n",
    "    for i in range(5):\n",
    "        print(pag.position())\n",
    "        pag.moveTo(shift[0]//5 + pag.position()[0], shift[1]//5 + pag.position()[1])\n",
    "#     pag.moveTo(shift[0], shift[1])\n",
    "\n",
    "\n",
    "def mouse_control(b):\n",
    "\n",
    "#     cap = cv2.VideoCapture(0) \n",
    "#     cap.set(3, 640) # Width\n",
    "#     cap.set(4, 480) # Lenght\n",
    "#     cap.set(10, 100) # Brightness\n",
    "#     mpHands = mp.solutions.hands\n",
    "#     hands = mpHands.Hands(False)\n",
    "\n",
    "    sensetive = 1\n",
    "    pag.moveTo(1000,500)\n",
    "    pag.FAILSAFE = False\n",
    "    weigth, height = pag.size()\n",
    "    print(\"-----\",weigth,\"----\")\n",
    "    koef = [weigth*sensetive,height*sensetive]\n",
    "    pred_x, pred_y, now_x, now_y = 0,0,0,0    \n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img,1) # Mirror flip\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    if results.multi_hand_landmarks:\n",
    "#         print(results.multi_hand_landmarks[8])\n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "            try:\n",
    "                lm = handLms.landmark[8]\n",
    "                now_x, now_y = lm.x, lm.y\n",
    "            except IndexErrror:\n",
    "                pass  \n",
    "\n",
    "\n",
    "    while Result_chek(net(torch.tensor(b))) != \"Fist\":\n",
    "        success, img = cap.read()\n",
    "        img = cv2.flip(img,1) # Mirror flip\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(imgRGB)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for handLms in results.multi_hand_landmarks:\n",
    "                lm = handLms.landmark[8]\n",
    "                now_x, now_y = lm.x, lm.y\n",
    "                x,y = pred_x - now_x,  now_y - pred_y \n",
    "                \n",
    "                b = []\n",
    "                for id, lmt in enumerate(handLms.landmark):\n",
    "                    b.append(lmt.x)\n",
    "                    b.append(lmt.y)\n",
    "#                 cv2.putText(img, Result_chek(net(torch.tensor(b))), (200,30), cv2.FONT_HERSHEY_PLAIN,2, (25,20,0),2)\n",
    "                    \n",
    "                #func place\n",
    "                try:\n",
    "                    smooth_mouse(now_x, now_y, pred_x, pred_y, koef)\n",
    "                except BaseException:\n",
    "                    print(\"out of border\")\n",
    "    #                 cap.release()\n",
    "    #                 cv2.waitKey(1)   \n",
    "    #                 break\n",
    "                    pag.moveTo(1000,500)\n",
    "                pred_x, pred_y = now_x, now_y\n",
    "        if keyboard.is_pressed('esc'):  # if key 'esc' is pressed\n",
    "            cap.release()\n",
    "            cv2.waitKey(1)   \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "72b401c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import os\n",
    "import sys \n",
    "\n",
    "\n",
    "# Подключаем камеру\n",
    "cap = cv2.VideoCapture(0) \n",
    "cap.set(3, 640) # Width\n",
    "cap.set(4, 480) # Lenght\n",
    "cap.set(10, 100) # Brightness\n",
    "\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(False)\n",
    "npDraw = mp.solutions.drawing_utils\n",
    "pTime = 0\n",
    "cTime = 0\n",
    "data = []\n",
    " #Зацикливаем получение кадров от камеры\n",
    "while True: \n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img,1) # Mirror flip\n",
    "    cx8=0\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    pred2 = []\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "#             print(\"handLms  \", handLms.landmark[1])\n",
    "            b = []\n",
    "            for id, lm in enumerate(handLms.landmark):\n",
    "                h,w,c = img.shape\n",
    "                cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "                b.append(lm.x)\n",
    "                b.append(lm.y)\n",
    "                if id == 8:\n",
    "                    cx8 = cx\n",
    "                # print(id, lm)\n",
    "                if  id == 8: #id == 12\n",
    "                    cv2.circle(img, (cx,cy),10,(255,0,255),cv2.FILLED)\n",
    "            if len(b) == 42:\n",
    "                pred = net(torch.tensor(b))\n",
    "                pred2 = pred.detach().numpy()\n",
    "            cv2.putText(img, Result_chek(net(torch.tensor(b))), (200,30), cv2.FONT_HERSHEY_PLAIN,2, (25,20,0),2)\n",
    "            \n",
    "            if Result_chek(net(torch.tensor(b))) != \"Fist\": # управление мышью\n",
    "                mouse_control(b)\n",
    "                \n",
    "                \n",
    "            npDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)\n",
    "            \n",
    "    \n",
    "\n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime\n",
    "    exist = [float(i) for i in pred2]\n",
    "#     cv2.putText(img, str(exist),(10,30), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0), 2) # ФреймРейт\n",
    "#     cv2.putText(img, str(cx8),(100,30), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0), 2)\n",
    "    cv2.imshow('python', img)\n",
    "    if cv2.waitKey(20) == 27: # exit on ESC\n",
    "        break\n",
    "        \n",
    "cv2.destroyWindow(\"python\")\n",
    "cap.release()\n",
    "cv2.waitKey(1)\n",
    "# print(a) # a is massive of data we need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9633464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    pag.hotkey('ctrl', 'shift', 'esc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7c13359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cfa2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
